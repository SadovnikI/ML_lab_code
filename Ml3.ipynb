{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvELBwsD7gob"
      },
      "source": [
        "# Neural Collaborative Filtering (NCF)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goMOkkqN7gof"
      },
      "source": [
        "**Matrix factorization algorithm**\n",
        "\n",
        "NCF is a neural matrix factorization model, which ensembles Generalized Matrix Factorization (GMF) and Multi-Layer Perceptron (MLP) to unify the strengths of linearity of MF and non-linearity of MLP for modelling the user–item latent structures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYslBOAK7goc"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZFVNnr27god",
        "outputId": "3f3a3c6a-6c21-40dd-e2ec-f85a8666825c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/anta/notebooks/Environments/gpu-env/lib/python3.7/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
            "  from pyarrow import HadoopFileSystem\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System version: 3.7.5 (default, Dec  9 2021, 17:04:37) \n",
            "[GCC 8.4.0]\n",
            "Pandas version: 1.3.5\n",
            "Tensorflow version: 2.7.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import papermill as pm\n",
        "import scrapbook as sb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from recommenders.utils.timer import Timer\n",
        "from recommenders.models.ncf.ncf_singlenode import NCF\n",
        "from recommenders.models.ncf.dataset import Dataset as NCFDataset\n",
        "from recommenders.datasets import movielens\n",
        "from recommenders.datasets.python_splitters import python_chrono_split\n",
        "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k,\n",
        "                                                     recall_at_k, get_top_k_items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ],
        "id": "4i-vGHmb7goe"
      },
      "outputs": [],
      "source": [
        "TOP_K = 10\n",
        "\n",
        "MOVIELENS_DATA_SIZE = '100k'\n",
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rR1BM8D7gog"
      },
      "source": [
        "## NCF movie recommender\n",
        "\n",
        "### Load and split data\n",
        "\n",
        "We split the data chronologically using python_chrono_split to achieve a 75/25% training and test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIne22XU7gog",
        "outputId": "9604317e-d324-4a9c-c799-6fe7e3576a42"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.81k/4.81k [00:00<00:00, 16.9kKB/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3.0</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3.0</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1.0</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2.0</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1.0</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  rating  timestamp\n",
              "0     196     242     3.0  881250949\n",
              "1     186     302     3.0  891717742\n",
              "2      22     377     1.0  878887116\n",
              "3     244      51     2.0  880606923\n",
              "4     166     346     1.0  886397596"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = movielens.load_pandas_df(\n",
        "    size=MOVIELENS_DATA_SIZE,\n",
        "    header=[\"userID\", \"itemID\", \"rating\", \"timestamp\"]\n",
        ")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ojif1sG7goh"
      },
      "outputs": [],
      "source": [
        "train, test = python_chrono_split(df, 0.75)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AmQ0POo7goh"
      },
      "source": [
        "Filter out any users or items in the test set that do not appear in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84Tq7BBq7goh"
      },
      "outputs": [],
      "source": [
        "test = test[test[\"userID\"].isin(train[\"userID\"].unique())]\n",
        "test = test[test[\"itemID\"].isin(train[\"itemID\"].unique())]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G8TpK4g7goi"
      },
      "source": [
        "Write datasets to csv files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzO64dFw7goi"
      },
      "outputs": [],
      "source": [
        "train_file = \"./train.csv\"\n",
        "test_file = \"./test.csv\"\n",
        "leave_one_out_test_file = \"./leave_one_out_test.csv\"\n",
        "train.to_csv(train_file, index=False)\n",
        "test.to_csv(test_file, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG0ayBI77goi"
      },
      "source": [
        "Here we use NCF Dataset data structure to make it easier to make matrixes for matrix factorization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Jdb2aft7goi",
        "outputId": "dc124713-5bb0-4f38-c854-28e407189983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indexing ./train.csv ...\n",
            "Indexing ./leave_one_out_test.csv ...\n",
            "Indexing ./leave_one_out_test_full.csv ...\n"
          ]
        }
      ],
      "source": [
        "data = NCFDataset(train_file=train_file, test_file=leave_one_out_test_file, overwrite_test_file_full=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-kcIQY37goi"
      },
      "source": [
        "### Train NCF model\n",
        "The NCF are:\n",
        "\n",
        "`n_factors`, which controls the dimension of the latent space. Usually, the quality of the training set predictions grows with as n_factors gets higher.\n",
        "\n",
        "`layer_sizes`, sizes of input layer (and hidden layers) of MLP, input type is list.\n",
        "\n",
        "`n_epochs`, which defines the number of iteration of the SGD procedure.\n",
        "Note that both parameter also affect the training time.\n",
        "\n",
        "`model_type`, we can train single `\"MLP\"`, `\"GMF\"` or combined model `\"NCF\"` by changing the type of model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chsz-aWZ7goj"
      },
      "outputs": [],
      "source": [
        "model = NCF (\n",
        "    n_users=data.n_users,\n",
        "    n_items=data.n_items,\n",
        "    model_type=\"NeuMF\",\n",
        "    n_factors=4,\n",
        "    layer_sizes=[16,8,4],\n",
        "    n_epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=1e-3,\n",
        "    verbose=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHbnlOq17goj"
      },
      "source": [
        "## Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcy8CFcZ7goj"
      },
      "source": [
        "### Prediction\n",
        "\n",
        "`predict` returns an internal object Prediction which can be easily converted back to a dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhYNr_GU7goj",
        "outputId": "9a0258af-fd94-434a-ebdb-65ba581bc221"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>0.029068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.624769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.234142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.101384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>0.067458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userID  itemID  prediction\n",
              "0     1.0   149.0    0.029068\n",
              "1     1.0    88.0    0.624769\n",
              "2     1.0   101.0    0.234142\n",
              "3     1.0   110.0    0.101384\n",
              "4     1.0   103.0    0.067458"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = [[row.userID, row.itemID, model.predict(row.userID, row.itemID)]\n",
        "               for (_, row) in test.iterrows()]\n",
        "\n",
        "\n",
        "predictions = pd.DataFrame(predictions, columns=['userID', 'itemID', 'prediction'])\n",
        "predictions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxNkwCcT7goj"
      },
      "source": [
        "### Generic Evaluation\n",
        "We remove rated movies in the top k recommendations\n",
        "To compute ranking metrics, we need predictions on all user, item pairs. We remove though the items already watched by the user, since we choose not to recommend them again."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users, items, preds = [], [], []\n",
        "item = list(train.itemID.unique())\n",
        "for user in train.userID.unique():\n",
        "    user = [user] * len(item)\n",
        "    users.extend(user)\n",
        "    items.extend(item)\n",
        "    preds.extend(list(model.predict(user, item, is_list=True)))\n",
        "\n",
        "all_predictions = pd.DataFrame(data={\"userID\": users, \"itemID\":items, \"prediction\":preds})\n",
        "\n",
        "merged = pd.merge(train, all_predictions, on=[\"userID\", \"itemID\"], how=\"outer\")\n",
        "all_predictions = merged[merged.rating.isnull()].drop('rating', axis=1)"
      ],
      "metadata": {
        "id": "eglOalW6DrK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kboVUbwJ7gok",
        "outputId": "9209e0cc-45cd-499b-c1b5-dc0a351b0450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAP:\t0.048144\n",
            "NDCG:\t0.198384\n",
            "Precision@K:\t0.176246\n",
            "Recall@K:\t0.098700\n"
          ]
        }
      ],
      "source": [
        "\n",
        "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "\n",
        "print(\"MAP:\\t%f\" % eval_map,\n",
        "      \"NDCG:\\t%f\" % eval_ndcg,\n",
        "      \"Precision@K:\\t%f\" % eval_precision,\n",
        "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And same metrics for TOP_K = 100"
      ],
      "metadata": {
        "id": "rGeQVbMP_K7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=100)\n",
        "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=100)\n",
        "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=100)\n",
        "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=100)\n",
        "\n",
        "print(\"MAP:\\t%f\" % eval_map,\n",
        "      \"NDCG:\\t%f\" % eval_ndcg,\n",
        "      \"Precision@K:\\t%f\" % eval_precision,\n",
        "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeFAzqIW_csr",
        "outputId": "298e485c-2d67-4707-b361-4df8c4d888d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP:\t0.104101\n",
            "NDCG:\t0.175529\n",
            "Precision@K:\t0.118462\n",
            "Recall@K:\t0.327749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "GmJpAua6-abg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, NCF gives a bit worse results in comperison to Standard-VAE models. Specifically, the results of evaluting the test set, for the the 3 different approaches, are:\n",
        "\n",
        "| Model                                           | Metric          | Value     |\n",
        "|--------------------------------------------------|------------------|-----------|\n",
        "| **Standard-VAE (without annealing, β=1) - 100**  | MAP@100          | 0.171624  |\n",
        "|                                                  | NDCG@100         | 0.393328  |\n",
        "|                                                  | Precision@100    | 0.231867  |\n",
        "|                                                  | Recall@100       | 0.319650  |\n",
        "| **Standard-VAE (without annealing, β=1) - 10**   | MAP@10           | 0.066183  |\n",
        "|                                                  | NDCG@10          | 0.496464  |\n",
        "|                                                  | Precision@10     | 0.473000  |\n",
        "|                                                  | Recall@10        | 0.101120  |\n",
        "| **Standard-VAE (with annealing, optimal β) - 100**| MAP@100          | 0.128121  |\n",
        "|                                                  | NDCG@100         | 0.312319  |\n",
        "|                                                  | Precision@100    | 0.191383  |\n",
        "|                                                  | Recall@100       | 0.224346  |\n",
        "| **Standard-VAE (with annealing, optimal β) - 10** | MAP@10           | 0.041101  |\n",
        "|                                                  | NDCG@10          | 0.406207  |\n",
        "|                                                  | Precision@10     | 0.321167  |\n",
        "|                                                  | Recall@10        | 0.091352  |\n",
        "| **Neural Collaborative Filtering (NCF) - 10**     | MAP              | 0.048144  |\n",
        "|                                                  | NDCG             | 0.198384  |\n",
        "|                                                  | Precision@K      | 0.176246  |\n",
        "|                                                  | Recall@K         | 0.098700  |\n",
        "| **Neural Collaborative Filtering (NCF) - 100**    | MAP@100          | 0.104101  |\n",
        "|                                                  | NDCG@100         | 0.175529  |\n",
        "|                                                  | Precision@100    | 0.118462  |\n",
        "|                                                  | Recall@100       | 0.327749  |\n",
        "\n",
        "\n",
        "## Model Comparison:\n",
        "\n",
        "### 1. Standard-VAE vs. NCF at Cutoff 10:\n",
        "- **NCF:**\n",
        "  - MAP: 0.048144, NDCG: 0.198384, Precision@K: 0.176246, Recall@K: 0.098700.\n",
        "- **Standard-VAE (without annealing, β=1):**\n",
        "  - MAP: 0.066183, NDCG: 0.496464, Precision@10: 0.473000, Recall@10: 0.101120.\n",
        "- **Observation:**\n",
        "  - Standard-VAE performs better in terms of MAP, NDCG, and precision at cutoff 10.\n",
        "  - NCF has a competitive recall value but lags in other metrics.\n",
        "\n",
        "### 2. Standard-VAE (with annealing, optimal β) vs. NCF at Cutoff 100:\n",
        "- **NCF:**\n",
        "  - MAP@100: 0.104101, NDCG@100: 0.175529, Precision@100: 0.118462, Recall@100: 0.327749.\n",
        "- **Standard-VAE (with annealing, optimal β):**\n",
        "  - MAP@100: 0.128121, NDCG@100: 0.312319, Precision@100: 0.191383, Recall@100: 0.224346.\n",
        "- **Observation:**\n",
        "  - Standard-VAE performs better in terms of MAP, NDCG, and precision at cutoff 100.\n",
        "  - NCF excels in recall but lags behind in other metrics.\n",
        "\n",
        "## Summary:\n",
        "\n",
        "- **Standard-VAE Strengths:**\n",
        "  - Performs well at both cutoff 10 and cutoff 100.\n",
        "  - Higher precision and NDCG values compared to NCF.\n",
        "\n",
        "- **NCF Strengths:**\n",
        "  - Competitive recall values, especially at cutoff 100.\n",
        "  - Potential for improvement in precision and MAP.\n",
        "\n",
        "- **Considerations:**\n",
        "  - The choice between models depends on specific use case requirements.\n",
        "  - Further experimentation and tuning are recommended for both models to enhance overall performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ii7eGMCO-dSB"
      }
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "interpreter": {
      "hash": "3a9a0c422ff9f08d62211b9648017c63b0a26d2c935edc37ebb8453675d13bb5"
    },
    "kernelspec": {
      "display_name": "reco_gpu",
      "language": "python",
      "name": "conda-env-reco_gpu-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
